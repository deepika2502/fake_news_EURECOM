{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c8ce1e7",
   "metadata": {},
   "source": [
    "# Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c581a899",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-26 18:59:43.706293: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-26 18:59:43.706439: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets, transforms as T\n",
    "from torchvision.datasets import FakeData\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from oauth2client.client import GoogleCredentials\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Softmax\n",
    "from torch.nn import Module\n",
    "from torch.optim import SGD\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.nn.init import kaiming_uniform_\n",
    "from torch.nn.init import xavier_uniform_\n",
    "from sklearn.metrics import accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf82bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "#Clear warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion() \n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29437ec5",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "644ea04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path =  'data.csv'\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e53b33f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author                  16096\n",
       "clean_title             17622\n",
       "created_utc             17622\n",
       "domain                  16750\n",
       "hasImage                17622\n",
       "id                      17622\n",
       "image_url               17603\n",
       "linked_submission_id      872\n",
       "num_comments            16750\n",
       "score                   17622\n",
       "subreddit               17622\n",
       "title                   17622\n",
       "upvote_ratio            16750\n",
       "2_way_label             17622\n",
       "3_way_label             17622\n",
       "6_way_label             17622\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e3ae161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n",
      "[0 2 1]\n",
      "[0 1 2 5 4 3]\n"
     ]
    }
   ],
   "source": [
    "print(df['2_way_label'].unique())\n",
    "print(df['3_way_label'].unique())\n",
    "print(df['6_way_label'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10476623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 in 2 way: 6951\n",
      "Class 1 in 2 way: 10671\n",
      "\n",
      "\n",
      "Class 0 in 3 way: 10671\n",
      "Class 1 in 3 way: 917\n",
      "Class 2 in 3 way: 6034\n",
      "\n",
      "\n",
      "Class 0 in 6 way: 10671\n",
      "Class 1 in 6 way: 851\n",
      "Class 2 in 6 way: 3447\n",
      "Class 3 in 6 way: 590\n",
      "Class 4 in 6 way: 872\n",
      "Class 5 in 6 way: 1191\n"
     ]
    }
   ],
   "source": [
    "print(\"Class 0 in 2 way: \"+ str(sum(df['2_way_label'] == 0)))\n",
    "print(\"Class 1 in 2 way: \"+ str(sum(df['2_way_label'] == 1)))\n",
    "print(\"\\n\\nClass 0 in 3 way: \"+ str(sum(df['3_way_label'] == 0)))\n",
    "print(\"Class 1 in 3 way: \"+ str(sum(df['3_way_label'] == 1)))\n",
    "print(\"Class 2 in 3 way: \"+ str(sum(df['3_way_label'] == 2)))\n",
    "print(\"\\n\\nClass 0 in 6 way: \"+ str(sum(df['6_way_label'] == 0)))\n",
    "print(\"Class 1 in 6 way: \"+ str(sum(df['6_way_label'] == 1)))\n",
    "print(\"Class 2 in 6 way: \"+ str(sum(df['6_way_label'] == 2)))\n",
    "print(\"Class 3 in 6 way: \"+ str(sum(df['6_way_label'] == 3)))\n",
    "print(\"Class 4 in 6 way: \"+ str(sum(df['6_way_label'] == 4)))\n",
    "print(\"Class 5 in 6 way: \"+ str(sum(df['6_way_label'] == 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c8c76c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['hasImage'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fbe9b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_title'].isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc01ebd",
   "metadata": {},
   "source": [
    "# Image Embeddings using pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9552f056",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: all CUDA-capable devices are busy or unavailable\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_39078/3614072443.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mresnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mimage_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mimage_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m         \"\"\"\n\u001b[0;32m--> 688\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mxpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    599\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m         \"\"\"\n\u001b[0;32m--> 688\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mxpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: all CUDA-capable devices are busy or unavailable\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "resnet = models.resnet50(pretrained=True)\n",
    "image_model = torch.nn.Sequential(*list(resnet.children())[:-1])\n",
    "image_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c93621",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply transformations to the image\n",
    "class LoadImage(Dataset):\n",
    "\n",
    "    def __init__(self, root, csv_path, transform=None):\n",
    "        self.root = root\n",
    "        self.image_dir = root\n",
    "        self.csv_path = csv_path\n",
    "        self.image_files = pd.read_csv(csv_path).iloc[:, 5]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        #return len(self.data) #self.data is not defined\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open('images/' + self.image_files[index] + '.jpg').convert(\"RGB\")\n",
    "        #label = self.data[index] # self.data is not defined\n",
    "        #image = transform(image)\n",
    "        image = self.transform(image)\n",
    "        return (image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc9ea8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([T.Resize(256), T.CenterCrop(224), T.ToTensor(), \n",
    "                       T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2a315c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = LoadImage('images',path, transform= transform)\n",
    "im_loader = DataLoader(dset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737ec88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature extraction\n",
    "image_model.eval()\n",
    "image_embeddings = []\n",
    "for batch in im_loader:\n",
    "  #image = batch\n",
    "  with torch.no_grad(): # we don't need the gradients because we are not training\n",
    "    # both the image_model and images need to be on the same device to compute (here, they are on GPU with .cuda() function).\n",
    "    output = image_model(batch.cuda()) # shape (batch_size, 512, 1, 1)\n",
    "  output = output.squeeze() # shape (btach_size, 512)\n",
    "  image_embeddings+=output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6460f504",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(image_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4472b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_embeddings = (np.array([i.cpu().detach().numpy() for i in image_embeddings])) \n",
    "image_embeddings = torch.tensor(image_embeddings)\n",
    "image_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d19fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_embeddings = image_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2577f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(combined_embeddings), len(combined_embeddings[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1aef4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_embeddings = np.asarray(combined_embeddings)\n",
    "combined_embeddings = torch.tensor(np.array([combined_embeddings]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538eae3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined_embeddings.shape)\n",
    "print(combined_embeddings.shape[2])\n",
    "print(combined_embeddings.type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca3770f",
   "metadata": {},
   "source": [
    "# Dataset and Dataloader using Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f075b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageSentenceDataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_path, embedding, transform = transforms.ToTensor()):\n",
    "        self.csv_path = csv_path\n",
    "        self.transform = transform\n",
    "        self.embeddings = embedding\n",
    "        self.labels = pd.read_csv(csv_path).iloc[:, 15]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #Sentence\n",
    "        label = self.labels[index]\n",
    "        embedding = self.embeddings[index]\n",
    "        return (embedding, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7cd8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path =  'data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561fbe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_dataset_from_csv = ImageSentenceDataset(path,combined_embeddings[0],\n",
    "                                               transform= transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa6cdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(custom_dataset_from_csv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b849679",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train and test splits\n",
    "train_set, test_set, val_set = torch.utils.data.random_split(custom_dataset_from_csv, [17622-3000, 1500, 1500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990ae472",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_set), len(test_set), len(val_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23842c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_dataset_loader = torch.utils.data.DataLoader(dataset=train_set,\n",
    "                                                    batch_size=28,\n",
    "                                                    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a1164e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just confirm what you see here\n",
    "for em, label in (custom_dataset_loader):\n",
    "  print(em, em.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdc13e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define MLP\n",
    "class MLP(Module):\n",
    "    # define model elements\n",
    "    def __init__(self, n_inputs):\n",
    "        super(MLP, self).__init__()\n",
    "        # input to first hidden layer\n",
    "        self.hidden1 = Linear(n_inputs, 100)\n",
    "        kaiming_uniform_(self.hidden1.weight, nonlinearity='relu')\n",
    "        self.act1 = ReLU()\n",
    "        # second hidden layer\n",
    "        self.hidden2 = Linear(100, 30)\n",
    "        kaiming_uniform_(self.hidden2.weight, nonlinearity='relu')\n",
    "        self.act2 = ReLU()\n",
    "        self.hidden3 = Linear(30, 6)\n",
    "        kaiming_uniform_(self.hidden3.weight, nonlinearity='relu')\n",
    "        self.act3 = ReLU()\n",
    "        # third hidden layer and output\n",
    "        self.hidden4 = Linear(6, 6)\n",
    "        xavier_uniform_(self.hidden4.weight)\n",
    "        self.act4 = Softmax(dim=1)\n",
    "\n",
    "    # forward propagate input\n",
    "    def forward(self, X):\n",
    "        # input to first hidden layer\n",
    "        X = self.hidden1(X)\n",
    "        X = self.act1(X)\n",
    "        # second hidden layer\n",
    "        X = self.hidden2(X)\n",
    "        X = self.act2(X)\n",
    "        # output layer\n",
    "        X = self.hidden3(X)\n",
    "        X = self.act3(X)\n",
    "        X = self.hidden4(X)\n",
    "        X = self.act4(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928c0d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(combined_embeddings.shape[2]).to(device)\n",
    "# train the model\n",
    "#train_model(custom_dataset_loader, model)\n",
    "optimizer = torch.optim.Adam(model.parameters(), amsgrad = True)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2fe67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a training function\n",
    "def train(epoch, log_interval=200):\n",
    "    # Set model to training mode\n",
    "    model.train()\n",
    "    for epoch in range(epoch):\n",
    "        # Loop over each batch from the training set\n",
    "        for batch_idx, (data, target) in enumerate(custom_dataset_loader):\n",
    "            # Copy data to GPU if needed\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            # Zero gradient buffers\n",
    "            optimizer.zero_grad() \n",
    "            # Pass data through the network\n",
    "            output = model(data)\n",
    "            # Calculate loss\n",
    "            loss = criterion(output, target)\n",
    "            # Backpropagate\n",
    "            loss.backward()        \n",
    "            # Update weights\n",
    "            optimizer.step()\n",
    "            \n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(custom_dataset_loader.dataset),\n",
    "                    100. * batch_idx / len(custom_dataset_loader), loss.data.item()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6031f33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(epoch=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10db95c",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4270d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation of model\n",
    "def evaluate_model(test_dl, model):\n",
    "    predictions, actuals = list(), list()\n",
    "    for i, (inputs, targets) in enumerate(test_dl):\n",
    "        # evaluate the model on the test set\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        yhat = model(inputs)\n",
    "        # retrieve numpy array\n",
    "        yhat = yhat.cpu().detach().numpy()\n",
    "        actual = targets.cpu().numpy()\n",
    "        # convert to class labels\n",
    "        yhat = np.argmax(yhat, axis=1)\n",
    "        # reshape for stacking\n",
    "        actual = actual.reshape((len(actual), 1))\n",
    "        yhat = yhat.reshape((len(yhat), 1))\n",
    "        # store\n",
    "        predictions.append(yhat)\n",
    "        actuals.append(actual)\n",
    "    predictions, actuals = np.vstack(predictions), np.vstack(actuals)\n",
    "    # calculate accuracy\n",
    "    acc = accuracy_score(actuals, predictions)\n",
    "    report = classification_report(actuals, predictions)\n",
    "    return acc, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5e4a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_loader = torch.utils.data.DataLoader(dataset=test_set,\n",
    "                                                    batch_size=1024,\n",
    "                                                    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4073e9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, report = evaluate_model(test_dataset_loader, model)\n",
    "print(\"Accuracy and classification report\")\n",
    "print(acc)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a7fe26",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset_loader = torch.utils.data.DataLoader(dataset=val_set,\n",
    "                                                    batch_size=64,\n",
    "                                                    shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5330b39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, report = evaluate_model(val_dataset_loader, model)\n",
    "print(\"Accuracy and classification report\")\n",
    "print(acc)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
